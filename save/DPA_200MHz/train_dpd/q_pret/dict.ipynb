{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../q_pret_test'\n",
    "model_path = file_path + '/DPD_S_0_M_DGRU_H_8_F_50_P_486.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.rnn.rnn_cell_list.0.x2h.weight\n",
      "backbone.rnn.rnn_cell_list.0.x2h.bias\n",
      "backbone.rnn.rnn_cell_list.0.x2h.n_bits_w\n",
      "backbone.rnn.rnn_cell_list.0.x2h.n_bits_a\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.h2h.weight\n",
      "backbone.rnn.rnn_cell_list.0.h2h.bias\n",
      "backbone.rnn.rnn_cell_list.0.h2h.n_bits_w\n",
      "backbone.rnn.rnn_cell_list.0.h2h.n_bits_a\n",
      "backbone.rnn.rnn_cell_list.0.h2h.weight_quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.h2h.weight_quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.h2h.weight_quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.h2h.weight_quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.h2h.act_quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.h2h.act_quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.h2h.act_quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.h2h.act_quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.tanh.quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.tanh.quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.tanh.quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.tanh.quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.add.quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.add.quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.add.quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.add.quantizer.decimal_num\n",
      "backbone.rnn.rnn_cell_list.0.mul.quantizer.scale\n",
      "backbone.rnn.rnn_cell_list.0.mul.quantizer.pow2_scale\n",
      "backbone.rnn.rnn_cell_list.0.mul.quantizer.integer_num\n",
      "backbone.rnn.rnn_cell_list.0.mul.quantizer.decimal_num\n",
      "backbone.fc_out.weight\n",
      "backbone.fc_out.bias\n",
      "backbone.fc_out.n_bits_w\n",
      "backbone.fc_out.n_bits_a\n",
      "backbone.fc_out.weight_quantizer.scale\n",
      "backbone.fc_out.weight_quantizer.pow2_scale\n",
      "backbone.fc_out.weight_quantizer.integer_num\n",
      "backbone.fc_out.weight_quantizer.decimal_num\n",
      "backbone.fc_out.act_quantizer.scale\n",
      "backbone.fc_out.act_quantizer.pow2_scale\n",
      "backbone.fc_out.act_quantizer.integer_num\n",
      "backbone.fc_out.act_quantizer.decimal_num\n",
      "backbone.fc_hid.weight\n",
      "backbone.fc_hid.bias\n",
      "backbone.fc_hid.n_bits_w\n",
      "backbone.fc_hid.n_bits_a\n",
      "backbone.fc_hid.weight_quantizer.scale\n",
      "backbone.fc_hid.weight_quantizer.pow2_scale\n",
      "backbone.fc_hid.weight_quantizer.integer_num\n",
      "backbone.fc_hid.weight_quantizer.decimal_num\n",
      "backbone.fc_hid.act_quantizer.scale\n",
      "backbone.fc_hid.act_quantizer.pow2_scale\n",
      "backbone.fc_hid.act_quantizer.integer_num\n",
      "backbone.fc_hid.act_quantizer.decimal_num\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_state = torch.load(model_path, map_location='cpu')\n",
    "for key in model_state.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.scale\n",
      "tensor(0.0518692955)\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.pow2_scale\n",
      "tensor(0.0625000000)\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.integer_num\n",
      "tensor(3, dtype=torch.int32)\n",
      "backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.decimal_num\n",
      "tensor(4, dtype=torch.int32)\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.scale\n",
      "tensor([0.0148559781])\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.pow2_scale\n",
      "tensor([0.0156250000])\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.integer_num\n",
      "tensor([1], dtype=torch.int32)\n",
      "backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.decimal_num\n",
      "tensor([6], dtype=torch.int32)\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.scale\n",
      "tensor([0.0074279890])\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.pow2_scale\n",
      "tensor([0.0078125000])\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.integer_num\n",
      "tensor([0], dtype=torch.int32)\n",
      "backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.decimal_num\n",
      "tensor([7], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print_list = ['backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.scale', \n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.pow2_scale', \n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.integer_num',\n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer.decimal_num',\n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.scale',\n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.pow2_scale',\n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.integer_num',\n",
    "              'backbone.rnn.rnn_cell_list.0.x2h.act_quantizer.decimal_num', \n",
    "              'backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.scale',\n",
    "              'backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.pow2_scale',\n",
    "              'backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.integer_num',\n",
    "              'backbone.rnn.rnn_cell_list.0.sigmoid.quantizer.decimal_num',\n",
    "              ]\n",
    "for key in print_list:\n",
    "    print(key)\n",
    "    # set torch print precision\n",
    "    torch.set_printoptions(precision=10)\n",
    "    print(model_state[key])\n",
    "    # print(model_state[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity between two tensors\n",
    "def calc_similarity(tensor1, tensor2):\n",
    "    tensor1 = tensor1.flatten()\n",
    "    tensor2 = tensor2.flatten()\n",
    "    return torch.dot(tensor1, tensor2) / (torch.norm(tensor1) * torch.norm(tensor2))\n",
    "\n",
    "\n",
    "# calculate the loss of two tensors\n",
    "def calc_loss(tensor1, tensor2):\n",
    "    tensor1 = tensor1.flatten()\n",
    "    tensor2 = tensor2.flatten()\n",
    "    return torch.norm(tensor1 - tensor2) / torch.norm(tensor1)\n",
    "\n",
    "# calculate the identity ratio of two tensors\n",
    "def calc_identity_ratio(tensor1, tensor2):\n",
    "    tensor1 = tensor1.flatten()\n",
    "    tensor2 = tensor2.flatten()\n",
    "    \n",
    "    # if tensor1 - tensor2 is less than 1e-5, then we think they are the same\n",
    "    return torch.sum(torch.abs(tensor1 - tensor2) < 1e-4) / tensor1.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between backbone.rnn.rnn_cell_list.0.x2h.weight and backbone.rnn.rnn_cell_list.0.x2h.quantized_weight is 0.9999980926513672\n",
      "The loss between backbone.rnn.rnn_cell_list.0.x2h.weight and backbone.rnn.rnn_cell_list.0.x2h.quantized_weight is 0.0019843988120555878\n",
      "The identity ratio between backbone.rnn.rnn_cell_list.0.x2h.weight and backbone.rnn.rnn_cell_list.0.x2h.quantized_weight is 0.0416666679084301\n",
      "==================================================\n",
      "The similarity between backbone.rnn.rnn_cell_list.0.h2h.weight and backbone.rnn.rnn_cell_list.0.h2h.quantized_weight is 0.999998152256012\n",
      "The loss between backbone.rnn.rnn_cell_list.0.h2h.weight and backbone.rnn.rnn_cell_list.0.h2h.quantized_weight is 0.0019392884569242597\n",
      "The identity ratio between backbone.rnn.rnn_cell_list.0.h2h.weight and backbone.rnn.rnn_cell_list.0.h2h.quantized_weight is 0.0416666679084301\n",
      "==================================================\n",
      "The similarity between backbone.fc_out.weight and backbone.fc_out.quantized_weight is 0.9999988079071045\n",
      "The loss between backbone.fc_out.weight and backbone.fc_out.quantized_weight is 0.0015588727546855807\n",
      "The identity ratio between backbone.fc_out.weight and backbone.fc_out.quantized_weight is 0.25\n",
      "==================================================\n",
      "The similarity between backbone.fc_hid.weight and backbone.fc_hid.quantized_weight is 0.9999973177909851\n",
      "The loss between backbone.fc_hid.weight and backbone.fc_hid.quantized_weight is 0.002325731562450528\n",
      "The identity ratio between backbone.fc_hid.weight and backbone.fc_hid.quantized_weight is 0.109375\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for key in model_state.keys():\n",
    "    if 'quantized_weight' in key:\n",
    "        fp_weight_name = key.replace('quantized_weight', 'weight')\n",
    "        fp_weight = model_state[fp_weight_name]\n",
    "        q_weight = model_state[key]\n",
    "        \n",
    "        print(\"The similarity between {} and {} is {}\".format(fp_weight_name, key, calc_similarity(fp_weight, q_weight)))\n",
    "        print(\"The loss between {} and {} is {}\".format(fp_weight_name, key, calc_loss(fp_weight, q_weight)))\n",
    "        print(\"The identity ratio between {} and {} is {}\".format(fp_weight_name, key, calc_identity_ratio(fp_weight, q_weight)))\n",
    "        print('=' * 50)\n",
    "\n",
    "# print(calc_similarity(weight, qweight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procss saved acitivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/space/ali6/projects/OpenDPD/save/DPA_200MHz/train_dpd/q_pret'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone\n",
    "# backbone.rnn\n",
    "# backbone.rnn.rnn_cell_list\n",
    "# backbone.rnn.rnn_cell_list.0\n",
    "# backbone.rnn.rnn_cell_list.0.x2h\n",
    "# backbone.rnn.rnn_cell_list.0.x2h.weight_quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.x2h.act_quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.h2h\n",
    "# backbone.rnn.rnn_cell_list.0.h2h.weight_quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.h2h.act_quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.sigmoid\n",
    "# backbone.rnn.rnn_cell_list.0.sigmoid.quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.tanh\n",
    "# backbone.rnn.rnn_cell_list.0.tanh.quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.add\n",
    "# backbone.rnn.rnn_cell_list.0.add.quantizer\n",
    "# backbone.rnn.rnn_cell_list.0.mul\n",
    "# backbone.rnn.rnn_cell_list.0.mul.quantizer\n",
    "# backbone.fc_out\n",
    "# backbone.fc_out.weight_quantizer\n",
    "# backbone.fc_out.act_quantizer\n",
    "# backbone.fc_hid\n",
    "# backbone.fc_hid.weight_quantizer\n",
    "# backbone.fc_hid.act_quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_path = '/space/ali6/projects/OpenDPD/save/activations/activations.pt'\n",
    "at_fp_path = '/space/ali6/projects/OpenDPD/save/activations/activations_fp.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "act_state = torch.load(at_path, map_location='cpu')\n",
    "act_fp_state = torch.load(at_fp_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.rnn.rnn_cell_list.0.x2h\n",
      "backbone.rnn.rnn_cell_list.0.h2h\n",
      "backbone.fc_hid\n",
      "backbone.fc_out\n",
      "==================================================\n",
      "backbone.rnn.rnn_cell_list.0.x2h\n",
      "backbone.rnn.rnn_cell_list.0.h2h\n",
      "backbone.fc_hid\n",
      "backbone.fc_out\n"
     ]
    }
   ],
   "source": [
    "for key in act_state.keys():\n",
    "    print(key)\n",
    "print('=' * 50)\n",
    "for key in act_fp_state.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.rnn.rnn_cell_list.0.x2h\n",
      "torch.Size([7680, 24])\n",
      "--------------------------------------------------\n",
      "backbone.rnn.rnn_cell_list.0.h2h\n",
      "torch.Size([7680, 24])\n",
      "--------------------------------------------------\n",
      "backbone.fc_hid\n",
      "torch.Size([1, 7680, 8])\n",
      "--------------------------------------------------\n",
      "backbone.fc_out\n",
      "torch.Size([1, 7680, 2])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in act_state.keys():\n",
    "    print(key)\n",
    "    print(act_state[key].shape)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.rnn.rnn_cell_list.0.x2h\n",
      "torch.Size([7680, 24])\n",
      "--------------------------------------------------\n",
      "backbone.rnn.rnn_cell_list.0.h2h\n",
      "torch.Size([7680, 24])\n",
      "--------------------------------------------------\n",
      "backbone.fc_hid\n",
      "torch.Size([1, 7680, 8])\n",
      "--------------------------------------------------\n",
      "backbone.fc_out\n",
      "torch.Size([1, 7680, 2])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in act_fp_state.keys():\n",
    "    print(key)\n",
    "    print(act_fp_state[key].shape)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.rnn.rnn_cell_list.0.x2h\n",
      "The similarity between backbone.rnn.rnn_cell_list.0.x2h and backbone.rnn.rnn_cell_list.0.x2h is 0.5229849815368652\n",
      "The loss between backbone.rnn.rnn_cell_list.0.x2h and backbone.rnn.rnn_cell_list.0.x2h is 1.261439323425293\n",
      "The identity ratio between backbone.rnn.rnn_cell_list.0.x2h and backbone.rnn.rnn_cell_list.0.x2h is 0.00027669270639307797\n",
      "==================================================\n",
      "backbone.rnn.rnn_cell_list.0.h2h\n",
      "The similarity between backbone.rnn.rnn_cell_list.0.h2h and backbone.rnn.rnn_cell_list.0.h2h is 0.25607606768608093\n",
      "The loss between backbone.rnn.rnn_cell_list.0.h2h and backbone.rnn.rnn_cell_list.0.h2h is 3.620683431625366\n",
      "The identity ratio between backbone.rnn.rnn_cell_list.0.h2h and backbone.rnn.rnn_cell_list.0.h2h is 0.00018988715601153672\n",
      "==================================================\n",
      "backbone.fc_hid\n",
      "The similarity between backbone.fc_hid and backbone.fc_hid is 0.007444129791110754\n",
      "The loss between backbone.fc_hid and backbone.fc_hid is 2.499458074569702\n",
      "The identity ratio between backbone.fc_hid and backbone.fc_hid is 0.0001302083401242271\n",
      "==================================================\n",
      "backbone.fc_out\n",
      "The similarity between backbone.fc_out and backbone.fc_out is 0.8614733219146729\n",
      "The loss between backbone.fc_out and backbone.fc_out is 0.5693191885948181\n",
      "The identity ratio between backbone.fc_out and backbone.fc_out is 0.0010416667209938169\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# compare the similarity between activations and activations_fp\n",
    "for key in act_state.keys():\n",
    "    print(key)\n",
    "    print(\"The similarity between {} and {} is {}\".format(key, key, calc_similarity(act_state[key], act_fp_state[key])))\n",
    "    print(\"The loss between {} and {} is {}\".format(key, key, calc_loss(act_state[key], act_fp_state[key])))\n",
    "    print(\"The identity ratio between {} and {} is {}\".format(key, key, calc_identity_ratio(act_state[key], act_fp_state[key])))\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual the activation distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def plot_hist(data, bins=100, title=None, xlabel=None, ylabel=None, xlim=None, ylim=None, save_path=None):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.hist(data, bins=bins)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2542, -0.2650, -0.1250, -0.0066, -0.1606, -0.3841, -0.0135, -0.1079])\n",
      "tensor([-0.2230,  0.6963,  0.5281,  0.4963,  0.7205, -0.6970,  0.4622,  0.1651])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4)\n",
    "print(act_state['backbone.fc_hid'][0][22])\n",
    "print(act_fp_state['backbone.fc_hid'][0][22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import collections\n",
    "from typing import DefaultDict, Tuple, List, Dict\n",
    "from functools import partial\n",
    "\n",
    "def save_activations(\n",
    "        activations: DefaultDict,\n",
    "        name: str,\n",
    "        module: nn.Module,\n",
    "        inp: Tuple,\n",
    "        out: torch.Tensor\n",
    ") -> None:\n",
    "    \"\"\"PyTorch Forward hook to save outputs at each forward\n",
    "    pass. Mutates specified dict objects with each fwd pass.\n",
    "    \"\"\"\n",
    "    activations[name].append(out.detach().cpu())\n",
    "\n",
    "def register_activation_hooks(\n",
    "        model: nn.Module,\n",
    "        layers_to_save: List[str]\n",
    ") -> DefaultDict[List, torch.Tensor]:\n",
    "    \"\"\"Registers forward hooks in specified layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model:\n",
    "        PyTorch model\n",
    "    layers_to_save:\n",
    "        Module names within ``model`` whose activations we want to save.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    activations_dict:\n",
    "        dict of lists containing activations of specified layers in\n",
    "        ``layers_to_save``.\n",
    "    \"\"\"\n",
    "    activations_dict = collections.defaultdict(list)\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        print(name)\n",
    "        if name in layers_to_save:\n",
    "            module.register_forward_hook(\n",
    "                partial(save_activations, activations_dict, name)\n",
    "            )\n",
    "    return activations_dict\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Simple two layer conv net\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=(5, 5), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=(3, 3), stride=(2,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        z = F.relu(self.conv2(y))\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv1\n",
      "conv2\n"
     ]
    }
   ],
   "source": [
    "mdl = Net()\n",
    "to_save = [\"conv1\", \"conv2\"]\n",
    "\n",
    "# register fwd hooks in specified layers\n",
    "saved_activations = register_activation_hooks(mdl, layers_to_save=to_save)\n",
    "\n",
    "# run twice, then assert each created lists for conv1 and conv2, each with length 2\n",
    "num_fwd = 2\n",
    "images = [torch.randn(10, 3, 256, 256) for _ in range(num_fwd)]\n",
    "for _ in range(num_fwd):\n",
    "    mdl(images[_])\n",
    "\n",
    "assert len(saved_activations[\"conv1\"]) == num_fwd\n",
    "assert len(saved_activations[\"conv2\"]) == num_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 126, 126])\n",
      "torch.Size([10, 8, 62, 62])\n"
     ]
    }
   ],
   "source": [
    "print(saved_activations[\"conv1\"][0].shape)\n",
    "print(saved_activations[\"conv2\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
